2017-tica-metadynamics:
  pmid: 28383914
  doi: 10.1021/acs.jctc.7b00182

2016-commute-maps:
  doi: 10.1021/acs.jctc.6b00762
  tags: [msm-theory]
  description: |+
    Scale tIC coordinates by a function of the timescale.

2015-gaussian-msms:
  doi: 10.1063/1.4913214
  tags: [msm-theory]


2015-amino-acid-basis:
  doi: 10.1021/acs.jctc.5b00498
  tags: [msm-theory]
  description: |+
    Authors simulate individual (capped) amino acids for 1us / each and construct (mini-)MSMs on each one.
    They use the outerproduct of these mini-MSMs to serve as a basis set for peptides. MiniMSMs are on
    a grid in phi-psi angles. Since each miniMSM has approx 3 modes, the full basis would be 3^(N), which
    is way too big! They call the second and third modes "excited states" and use a basis set that contains
    a singly-exited residue. E.g. 11111 + [ [21111, 121111, 112111, 111211, ...] ].

    Alanine preceded by a proline is taken as a special case.

2016-husic-msms:
  doi: 10.1063/1.4967809
  tags: [msm-theory]
  description: |+
    The authors perform GMRQ cross validation on the twelve [2011-larsen-folding] folding trajectories to
    give guidelines for MSM construction.

    They present a flowchart for MSM construction that shows the three paths towards clustering: from
    an rmsd distance metric, from features, or from tICA learned on features.

    They introduce GMRQ cross validation in the tradition of [=44].

    They present results but stress that you have to do your own cross validataion to be sure. Some conclusions
    include: 1. tICA and PCA are better than direct clustering of features 2. when using tica, you can use kcenters,
    kmeans, or minibatch kmeans to the same effect

    On one protein (2p6j) they look at all different features and show that they vary a lot. It's unfortunate that
    this was only done on one protein.

  cites:
    - num: 41
      id: 2013-noe-variational
      why: Variational principle
    - num: 42
      why: Variational principle
      id: 2014-nuske-variational
    - num: 5
      id: 2008-anton
      why: Generated the trajectories.
    - num: 18
      id: 2011-larsen-folding
      why: Re-analyzed these simulations. "Diversity of proteins analyzed"
    - num: 44
      id: 2015-mcgibbon-gmrq
      why: Cross-validation




2015-schwantes-ktica:
  doi: 10.1021/ct5007357
  tags: [msm-theory]
  description: |+
    They introduce kernel tICA as an extension to tICA. This is useful to get non-linear solutions to
    the tICA equation. They claim you can estimate eigenprocesses without building an MSM.

    They briefly introduce the transfer operator. They introduce the variational principle of conformation
    dynamics per [=25]. They introduce tICA as maximizing the autocorrelation. They say that solutions to tICA
    are the same as solutions to the variational problem per [=28]. Linearity makes them crude solutions.

    They explain that a natural approach to introduce non-linearity is to expand the original representation
    into a higher dimensional space and do tICA there. They say this is impractical. The expanded space
    probably has to be huge. You can perform analysis in the big representation without explicitly representing it
    by using the "kernel trick". They reproduce an example of the kernel trick from [=39].

    They re-write the tICA problem only in terms of inner products so you can apply the kernel trick. They introduce
    normalization. They choose a gaussian kernel. They simulate a four-well potential, muller potential, alanine
    dipeptide, and fip35ww. They need to do MLE cross validation over parameters (kernel width and regularization
    strength).

    This uses so much RAM! Huge matrices to solve (that scale with the amount of data!!)

  cites:
    - id: 2014-msm-perspective
      num: 21
      why: Data needs analysis
    - id: 2011-prinz
      why: Details of transfer operator approach.
      num: 25
    - id: 2001-schutte-variational
      num: 33
      why: Details of transfer operator approach.
    - id: 2013-noe-variational
      num: 34
      why: |+
        "It was shown that a variational principle can be derived for the eignvalues of the transfer operator."
        The autocorelation of a function is less than the autocorrelation of the first dynamical eigenfunction
        of the transfer operator. This is used to argue that you don't have to estimate the operator itself.
        Just estimate its eigenfunctions
    - id: 2014-nuske-variational
      num: 35
      why: |+
        "Successfully constructed estimates of the top eigenfunctions in the span of a prespecified library of basis functions."
        Contrast with this work, which "does not require a predefined basis set"
    - num: 22
      why: Citing tICA
      id: 2013-schwantes-tica
    - num: 28
      why: Citing tICA
      id: 2013-noe-tica
      why: solutions to tica provide estimates of the slowest eigenfunctions of the transfer operator.
    - num: 36
      why: Citing tICA
      id: "doi:10.1103/PhysRevLett.72.3634"
    - num: 37
      why: Citing tICA
      id: "doi:10.1162/neco.2006.18.10.2495"
    - num: 39
      id: 1998-scholkopf-kernel-pca
      why: Used to introduce ther kernel trick.


1998-scholkopf-kernel-pca:
  doi: 10.1162/089976698300017467


2001-schutte-variational:
  tags: [msm-theory]
  doi: 10.1007/978-3-642-56589-2_9
  pages: {start: 191, end: 223}
  isbn: 978-3-642-62524-4
  description: |+
    Full treatment of transfer operator / propagator and build
    an MSM for a small RNA chain.

2015-shukla-msm-review:
  pmid: 25625937
  pmcid: PMC4333613
  doi: 10.1021/ar5002999

2016-noe-reversible-tica:
    tags: [msm-theory]
    arxiv: "1610.06773"
    doi: 10.1063/1.4979344
    pmid: 28433026
    cites:
      - id: "doi:10.1063/1.4934536"
        num: 46
        why: Reversibility makes analysis easier
      - num: 50
        id: 2013-noe-variational
        note: |+
          In remark 2.7, they say a "variational principle of conformation dynamics"
          can be formulated. There's not VAC. The title has "variational approach"
          but not to conformation.
      - num: 51
        id: 2013-noe-tica
        note: |+
          In this paper, they call it the "variational principle of conformation dynamics."
          There's no mention of variational approach or VAC.
      - num: 52
        id: 2014-nuske-variational
        note: |+
          In this paper, they say the old one was "variational principle for metastable stochastic processes"
          and they develop a "variational approach to molecular kinetics"

    description: |+
      Provides a better way of "symetrizing" tICA correlation matrix. In tICA, you assume that the dynamics
      are reversible. When we're learning from finite data, this reversibility isn't respected. Historically,
      you take your correlation matrix, add its transpose, and divide by two. This is an especially poor
      approximation if you have many short trajectories. This paper is analogous to the MLE method for
      symetrizing MSM counts matrices.

"doi:10.1063/1.4934536":
    doi: 10.1063/1.4934536
    description: Reversible estimates for MSMs


2010-everything-msm-afraid-ask:
    doi: 10.1016/j.ymeth.2010.06.002
    description: Review of MSMs intended for "non-experts".
      Obviously a little dated by now.
    tags: [msm-theory, review]

2013-milliseconds-folding:
    doi: 10.1016/j.sbi.2012.11.002
    description: The state of folding simulations as it was in 2013.
      Has a nice plot of folding time by year by lab. Discusses the state
      of MSMs for analysis. Maybe cite this if you're doing folding or want
      to talk about how timescales are getting longer (and analysis is getting
      harder). The references include "recommended readings", which is nice.
    tags: [msm-theory, perspective]

2014-msm-perspective:
    doi: 10.1063/1.4895044
    pmid: 24836551
    pmcid: PMC4124001
    description: |+
      Very good perspective on the importance of analysis (particularly MSM
      analysis) for understanding large, modern MD datasets. Money quote:
      "we believe that quantitative analysis has increasingly become a
      limiting factor in the application of MD"
    tags: [msm-theory, perspective]

2015-mcgibbon-gmrq:
    doi: 10.1063/1.4916292
    tags: [msm-theory, variational]

2014-nuske-variational:
    doi: 10.1021/ct4009156
    tags: [msm-theory, variational]
    description: |+
      This paper is largely redundant with [2013-noe-variational=65]. They cite it as such:
      "Following the recently introduced variational principle for metastable stochastic processes,(65)
      we propose a variational approach to molecular kinetics."

      They perform their variational approach on 2- and 10-alanine in addition to 1D potentials.

      This comes after tICA
      and cites [2013-schwantes-tica=57] and [2013-noe-tica=58] in the intro, but does
      nothing further with it. In particular, they don't note that tICA is just another
      choice of basis set.

      They cite their error paper [2010-msm-error=55].

2014-chodera-msm:
    doi: 10.1016/j.sbi.2014.04.002
    description: Overview of MSMs, stressing eigensystem and variational approach.
      Includes further reading suggestions.
    tags: [msm-theory, perspective]

2011-prinz:
    doi: 10.1063/1.3565032
    description: |+
      Fantastic in-depth intro to MSMs. Figure 1 in this paper is necessary for understanding
      eigenvectors. This defines and relates the propogator and transfer operator. This shows
      how we compute timescales from eigenvectors. This discusess state decomposition error
      and shows that many states are needed in transition regions.

      quote: it is clear that a “sufficiently fine” partitioning will be able to resolve “sufficient” detail
      [2010-msm-error].

      Cites [2004-nina-msm] for use of the term "MSM".

    tags: [msm-theory, review]

2014-kohlhoff-exacycle:
    doi: 10.1038/nchem.1821
    description: They used Google's Exacycle to do these simulations. You can cite
      this for more examples of distributed computing. It's ostensibly about GPCRs.
    tags: [distributed-computing]

2000-fah:
    doi: 10.1126/science.290.5498.1903
    description: |+
      The seminal Folding at Home paper. Cite this whenever you talk about distributed computing
      or Folding at Home.

      SETI@Home and distributed.net came before this.
    tags: [distributed-computing]

2008-anton:
    doi: 10.1145/1364782.1364802
    description: |+
      The seminal Anton paper. Cite this when talking about single, long
      trajectories or special-purpose hardware.
    tags: [md-sampling]

2010-gpugrid:
    doi: 10.1021/ci900455r
    description: GPUGRID intro paper. Cite this alongside FAH. They (probably)
      did GPU distributed computing before FAH.
    tags: [distributed-computing]

2009-friedrichs-gpu:
    doi: 10.1002/jcc.21209
    description: |+
      Probably the second instance of using GPUs for molecular dynamics. This became
      [OpenMM](openmm.org).
    tags: [md-sampling]

2007-stone-gpu:
    doi: 10.1002/jcc.20829
    description: |+
      (Probably) the first GPU accelerated MD paper. This is for NAMD.
    tags: [md-sampling]

2008-anderson-gpu:
    doi: 10.1016/j.jcp.2008.01.047
    description: |+
      They claim to be the first GPU accelerated MD engine too! Probably led to HOOMD, although they
      don't call it that in the paper.
    tags: [md-sampling]

2009-eastman-gpu:
    doi: 10.1002/jcc.21413
    description: |+
      Optimizing below-cutoff nonbonded calculations on the GPU by tricky
      memory and parallelization management. This was for OpenMM. This
      is not PME.
    cites:
      - id: 2009-friedrichs-gpu
      - id: 2007-stone-gpu
      - id: 2008-anderson-gpu
    tags: [md-sampling, md-algorithm]

#- 2014-msm-book:
#    title = {An Introduction to Markov State Models and Their Application
#        to Long Timescale Molecular Simulation},
#	volume = {797},
#	url = {http://publications.mi.fu-berlin.de/1360/},
#	publisher = {Springer},
#	author = {Bowman, G. R. and Pande, V. S. and No{\'e}, F.},
#	editor = {Bowman, G. R. and Pande, V. S. and No{\'e}, F.},
#	year = {2014}
#}

2015-ratematrix:
    doi: 10.1063/1.4926516
    tags: [msm-theory]

2005-pcca:
    doi: 10.1016/j.laa.2004.10.026
    description: |+
      PCCA group states based on an MSM transition matrix. Specifically,
      it uses the eigenspectrum to do the lumping. Cite this in the methods
      section of your paper if you use PCCA or PCCA+.
    tags: [msm-theory, msm-postprocessing]

2013-schwantes-tica:
    doi: 10.1021/ct300878a
    description: The Pande group introduces tica concomitantly with [2013-noe-tica].
      This paper uses PCA as inspiration and cites signal processing literature.
    tags: [msm-theory, tica]

2013-noe-tica:
    doi: 10.1063/1.4811489
    description: The Noe group introduces tica concomitantly with [2013-schwantes-tica].
      They use the variational approach from [2013-noe-variational] to derive the tICA
      equation. They cite a 2001 book about independent component analysis.
    tags: [msm-theory, tica]

2011-japan-tica:
    doi: 10.1063/1.3554380
    description: Probably the first application of tICA to MD.
    tags: [msm-theory, tica]

2013-noe-variational:
    doi: 10.1137/110858616
    tags: [msm-theory, variational]
    description: |+
      I think the point of this versus [2014-nuske-variational] is to be "protein agnostic".
      They allude to proteins, but say this is more general. Their example is a double-well
      potential.

      They introduce the propogator formalism and stipulate that dynamics can be seperated
      into "fast" and "slow" components. In contrast to a quantum mechanics Hamiltonian,
      we don't know the propogator here. You have to infer it from data.

      They claim the error bound derived in [2010-msm-error=34] is not constructive, whereas this method *is*
      constructive.

      Math section heavily cites [2010-msm-error=34].

      They adapt the Rayleigh variational principle from quantum mechanics, and cite [1989-szabo-ostlund-qm=43].
      They show that the autocorrelation of the true first dynamical eigenfunction is its
      eigenvalue, and an estimate of the first dynamical eigenfunction necessarily has a
      smaller eigenvalue. This sets the variational bound. In terms of names that don't seem
      to be used now that we're in the future: the Ritz method is for when you have no overlap
      integrals (e.g. MSMs) and the Roothan-Hall method is for when you do (tICA).

      They put it to the test on a double well potential. They use indicator basis functions to
      make an MSM; hermite basis functions so they still have no overlap integrals, but smooth
      functions; and gaussian basis functions (with overlap integrals). This must have
      come before tICA because there is no mention made of it, even though it would fit in nicely.

2010-msm-error:
    doi: 10.1137/090764049
    tags: [msm-theory]

1989-szabo-ostlund-qm:
    title: "Modern Quantum Chemistry: Introduction to Advanced Electronic Structure Theory"
    author:
      - {given: Attila, family: Szabo}
      - {given: Neil S., family: Ostlund}
    published-print: !!timestamp 1989-01-01
    publisher: "Courier Corporation"
    type: book
    isbn: 9780486691862
    tags: [qm]
    description: |+
      Cited by [2013-noe-variational] for Rayleigh variational method.

2016-sparsetica:
    arxiv: "1602.08776"
    tags: [msm-theory, tica, features]
    description: |+
      The authors argue for a definition of the reaction coordinate as the
      projection on the dominant eigenfunciton of the propogator. Notably,
      they say that path-based coordinates are no good, because progress
      is only defined along the path. They argue that the coordinate shouldn't
      depend on start and end points. They say the projection should
      be maximally predictive. This means finding the slowest modes.
      They note [2006-nadler-diffusion-maps=61] and
      [2011-rohrdanz-diffusion-maps=62] have used this definition.

      They go on to show tICA finds this reaction coordinate. To make tICA
      more interpretable, they develop an algorithm for introducing a sparsity
      pattern. It's a pseudo-l0 regularization (made smooth so the optimization works).

      They also use a unique dihedral featurization: instead of taking the sine and cosine
      to get around periodicity concerns; they project the values on a bunch of evenly
      spaced von-mises (periodic gaussians) distributions around the unit circle. Each
      dihedral is expanded into several numbers. It's like a smooth histogramming.
      This probably won't work as the number of dihedrals gets large (too many features).


2006-nadler-diffusion-maps:
    doi: 10.1016/j.acha.2005.07.004
    tags: [other-md-analysis]

2011-rohrdanz-diffusion-maps:
    doi: 10.1063/1.3569857
    tags: [other-md-analysis]

2013-diffusion-map-sampling:
  doi: 10.1021/jp401911h
  description: |+
    Use diffusion maps to run umberlla sampling

2014-prinz-rate:
  doi: 10.1103/PhysRevX.4.011020

#@inproceedings{2014-hmm,
#    Author = {McGibbon, Robert T. and Ramsundar, Bharath and Sultan, Mohammad
#        M. and Kiss, Gert and Pande, Vijay S.},
#    Booktitle = {Proceedings of The 31st International Conference on Machine
#        Learning},
#    Pages = {1197-1205},
#    Title = {Understanding Protein Dynamics with L1-Regularized Reversible
#        Hidden Markov Models},
#    Year = {2014},
#}

2012-drid:
    doi: 10.1021/ct3003145
    description: A unique featurization that encodes each atom by the
      first ~3 moments of its distribution of 1/distance to every other atom.
      Cite this if you use this featurization.
    tags: [features]

2004-swope-msm:
  tags: [msm-theory]
  doi: 10.1021/jp037421y
  description: |+
    The first MSM paper. Gets pretty much everything right. Except they're convinced that you need
    to do state exploration via NVT or NPT and then calculate transitions by launching bespoke
    NVE simulations. Obviously, we just run big NPT runs and use that for both state space
    exploration and counting transitions.

2014-mcgibbon-bic:
  doi: 10.1021/jp411822r
  tags: [msm, cross-validation]
  description: |+
    This is before [2015-mcgibbon-gmrq] GRMQ cross-validation. They explicitly find the volume of
    voronoi cells (in low number of tIC space) to find a likelihood. They use AIC/BIC
    to find the number of states to use. Finding volumes is tough and you still can't compare
    across protocols (so you can basically only scan number of states or clustering method),
    but! this was the first paper to seriously suggest using a smaller number of states
    to avoid overfitting.

2015-wetmsm:
  doi: 10.1021/ct5010017
  description: |+
    Solvent-shells featurization for including solvent in MSM construction.



2013-mcgibbon-kdml:
  doi: 10.1021/ct400132h
  description: |+
    Learn scaling of coordinates to better approximate kinetics? Redundant with tICA.



2014-mcgibbon-hmm:
  title: Understanding Protein Dynamics with L1-Regularized Reversible Hidden Markov Models
  author:
    - Robert McGibbon
    - Bharath Ramsundar
    - Mohammad Sultan
    - Gert Kiss
    - Vijay Pande
  booktitle: Proceedings of the 31st International Conference on Machine Learning
  pages: 1197--1205
  year: 2014
  editor: Eric P. Xing and Tony Jebara
  volume: 32
  number: 2
  series: Proceedings of Machine Learning Research
  address: Bejing, China
  month: 22--24 Jun
  publisher: PMLR
  url: http://proceedings.mlr.press/v32/mcgibbon14.html
  description: |+
    Use hidden markov models instead of discrete state MSMs.

2013-noe-hmm:
  doi: 10.1063/1.4828816

2012-eigenvalue-error:
  doi: 10.1137/100798910

2987-van-kampen-book:
  title: Stochastic Processes in Physics and Chemistry
  isbn: [0-444-52965-9; 1-281-00388-3]
  author:
    - N G Van-Kampen
  year:  1987

2008-protein-folding-problem:
  doi: 10.1146/annurev.biophys.37.092707.153558

1968-levinthal-paradox:
  container-title:
    short: J. Chim. Phys. Physico-Chim. Biol.
  volume: 65
  pages: 44--45
  published-print: !!timestamp 1968-01-01
  author:
    - {given: C, family: Levinthal}
  description: |+
    Taken from [Nature's protein folding focus](http://www.nature.com/nsmb/focus/proteinfolding/classics/early.html)

    Among the most widely cited-yet least read-papers in the field, partly owing to the difficulties in
    getting hold of them, Cyrus Levinthal used a simple model to show that a typical polypeptide chain
    cannot fold through an unbiased search of all conformational space on a reasonable timescale.
    This is commonly referred to as the "Levinthal's paradox", and led to the concept that proteins fold
    along discrete pathways. The first paper presents this idea and is usually cited, but the model is
    actually presented in the second one. Although the model was later shown to be overly simplistic,
    the work had a crucial role in directing the search and characterization of intermediate states.

1992-levinthal-paradox:
  description: |+
    Conformational space is huge, but proteins can fold very fast.
  pmcid: PMC48166
  pmid: 1729690
  author:
    - R. Zwanzig
    - A. Szabo
    - B. Bagchi
  title: Levinthal's paradox
  volume: 89
  number: 1
  pages: 20--22
  year: 1992
  journal: Proceedings of the National Academy of Sciences

2010-pande-folding:
  doi: 10.1103/PhysRevLett.105.198101
  pmid: 21231198
  description: |+
    Non-native interactions and misfolding

2009-md-perspective:
  doi: 10.1016/j.sbi.2009.03.004

2009-plenty-of-room-focus:
  doi: 10.1038/nnano.2009.356
  description: |+
    Editorial about [1960-plenty-of-room-at-the-bottom].

1960-plenty-of-room-at-the-bottom:
  title: There's Plenty of Room at the Bottom
  published-print: !!timestamp 1960-02-01
  issn: 0013-7812
  author:
    - {given: Richard, family: Feynman}
  journal: Engineering and Science
  volume: 23
  number: 5
  pages: 22--36

2010-schulten-challenges:
  doi: 10.1038/nphys1713
  description: |+
    Cited by [2014-msm-perspective] as highlighting analysis as a problem.

1999-schutte-msm:
  doi: 10.1006/jcph.1999.6231
  description: |+
    Maybe the first time conformations were discretized and a Markov
    operator was made.

1991-complex-protein-energy-landscapes:
  doi: 10.1126/science.1749933
  description: |+
    Cited by [2011-prinz] to say that there are many metastable states and many timescales.

2004-nina-msm:
  doi: 10.1063/1.1738647
