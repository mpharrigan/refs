

<!DOCTYPE html>
<html lang="en">
  <!-- This file is autogenerated! Don't edit it! -->
  <head>
    <!-- Required meta tags always come first -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>misc - Gitbib</title>

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.4/css/bootstrap.min.css">
    <style>
      body {
        position: relative;
        color: #111;
      }
      p.card-text{
        margin-bottom: 0.5rem;
      }
      h6.card-subtitle{
        margin-bottom: 0.5rem;
      }
    </style>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.0.0/jquery.min.js"></script>
    <script>
        // 0 - all implicitly enabled
        // 1 - enabled
        // 2 - hidden
        var tags = {
        'cheminformatics': 0,
        'deep-learning': 0,
        'machine-learning': 0,
        'misc': 0,
        };
        var all_tags = true;

        function tag_toggle(name) {
            if (all_tags) {
                for (var i in tags) {
                    tag_disable(i);
                    tags[i] = 2;
                }
                all_tags = false;
            }

            if (tags[name] === 1) {
                tag_disable(name);
                tags[name] = 2;
            } else if (tags[name] === 2) {
                tag_enable(name);
                tags[name] = 1;
            }
        }

        function tag_enable(name) {
            
                if (name === 'cheminformatics'){
                    
                      $('#n2016-aspuru-mol-feat').show();
                    
                    $('#cheminformatics').removeClass('tag-default').addClass('tag-primary')
                }
            
                if (name === 'deep-learning'){
                    
                      $('#n2016-guttenberg-deep-slow').show();
                    
                      $('#n2017-deep-lift').show();
                    
                      $('#n2016-neural-computers').show();
                    
                      $('#n2014-ganguli-saddle-points').show();
                    
                    $('#deep-learning').removeClass('tag-default').addClass('tag-primary')
                }
            
                if (name === 'machine-learning'){
                    
                      $('#n2016-guttenberg-deep-slow').show();
                    
                      $('#n2016-aspuru-mol-feat').show();
                    
                      $('#n2017-deep-lift').show();
                    
                      $('#n2016-neural-computers').show();
                    
                      $('#n2014-ganguli-saddle-points').show();
                    
                    $('#machine-learning').removeClass('tag-default').addClass('tag-primary')
                }
            
                if (name === 'misc'){
                    
                      $('#n2016-aspuru-mol-feat').show();
                    
                      $('#n2016-msm-cryptic-binding').show();
                    
                      $('#n2016-mbar-volumes').show();
                    
                      $('#safe-css-arxiv151106349').show();
                    
                      $('#n2014-ganguli-saddle-points').show();
                    
                    $('#misc').removeClass('tag-default').addClass('tag-primary')
                }
            
        }

        function tag_disable(name) {
            
            if (name === 'cheminformatics'){
                
                $('#n2016-aspuru-mol-feat').hide();
                $('#cheminformatics').removeClass('tag-primary').addClass('tag-default')
            }
            
            if (name === 'deep-learning'){
                
                $('#n2016-guttenberg-deep-slow').hide();
                
                $('#n2017-deep-lift').hide();
                
                $('#n2016-neural-computers').hide();
                
                $('#n2014-ganguli-saddle-points').hide();
                $('#deep-learning').removeClass('tag-primary').addClass('tag-default')
            }
            
            if (name === 'machine-learning'){
                
                $('#n2016-guttenberg-deep-slow').hide();
                
                $('#n2016-aspuru-mol-feat').hide();
                
                $('#n2017-deep-lift').hide();
                
                $('#n2016-neural-computers').hide();
                
                $('#n2014-ganguli-saddle-points').hide();
                $('#machine-learning').removeClass('tag-primary').addClass('tag-default')
            }
            
            if (name === 'misc'){
                
                $('#n2016-aspuru-mol-feat').hide();
                
                $('#n2016-msm-cryptic-binding').hide();
                
                $('#n2016-mbar-volumes').hide();
                
                $('#safe-css-arxiv151106349').hide();
                
                $('#n2014-ganguli-saddle-points').hide();
                $('#misc').removeClass('tag-primary').addClass('tag-default')
            }
            
        }
    </script>

  </head>
  <body data-spy="scroll" data-target="#navlist">
    <div class="container">
      <div class="row" style="margin-top: 1rem;">
        <div class="col-xs-12 col-lg-9">
            <h5><a class="text-muted" href="index.html">
                <i class="fa fa-home" aria-hidden="true"></i>
                gitbib
            </a> |
            All tags:
            
            <span class="tag tag-default" onclick="tag_toggle('cheminformatics')" id="cheminformatics">cheminformatics</span>
            
            <span class="tag tag-default" onclick="tag_toggle('deep-learning')" id="deep-learning">deep-learning</span>
            
            <span class="tag tag-default" onclick="tag_toggle('machine-learning')" id="machine-learning">machine-learning</span>
            
            <span class="tag tag-default" onclick="tag_toggle('misc')" id="misc">misc</span>
            
            </h5>
            
            
            
            <div class="card">
              <div class="card-block" id="n2017-baker-antibody-design">
                <h4 class="card-title">Computational design of trimeric influenza-neutralizing proteins targeting the hemagglutinin receptor binding site</h4>
                <h6 class="card-subtitle text-muted"><strong>2017-baker-antibody-design</strong></h6>
                <p class="card-text">Eva-Maria Strauch; Steffen M Bernard; David La; Alan J Bohn; Peter S Lee; Caitlin E Anderson; Travis Nieusma; Carly A Holstein; Natalie K Garcia; Kathryn A Hooper; Rashmi Ravichandran; Jorgen W Nelson; William Sheffler; Jesse D Bloom; Kelly K Lee; Andrew B Ward; Paul Yager; Deborah H Fuller; Ian A Wilson; David Baker</p>
                <p class="card-text">
                  
                  2017-06-12 (online)
                  
                  
                  
                </p>
                <p class="card-text">
                  <em>Nature Biotechnology (Nat. Biotechnol.)</em>.
                  35, 
                  7, 
                  667-671. 
                  <a href="https://dx.doi.org/10.1038/nbt.3907">doi:10.1038/nbt.3907</a>
                  
                </p>
                
                <h6 class="m-b-0"><strong style="color: #444">Description</strong></h6>
                <p class="card-text">Uses computation to design an antibody for influenza A</p>
<p class="card-text"></p>
                

                

                

                
              </div>
            </div>
            
            
            <div class="card">
              <div class="card-block" id="n2017-deep-lift">
                <h4 class="card-title">Learning Important Features Through Propagating Activation Differences</h4>
                <h6 class="card-subtitle text-muted"><strong>2017-deep-lift</strong></h6>
                <p class="card-text">Avanti Shrikumar; Peyton Greenside; Anshul Kundaje</p>
                <p class="card-text">
                  
                  2017-04-10 (online)
                  
                  
                  
                </p>
                <p class="card-text">
                  
                  
                  
                  
                  
                  <a href="https://arxiv.org/abs/1704.02685">arxiv:1704.02685</a>
                </p>
                
                <h6 class="m-b-0"><strong style="color: #444">Description</strong></h6>
                <p class="card-text">Decompose ouput predictions</p>
<p class="card-text"></p>
                

                

                

                
                <p class="card-text">
                  
                  <span class="tag tag-primary">machine-learning</span>
                  
                  <span class="tag tag-primary">deep-learning</span>
                  
                </p>
                
              </div>
            </div>
            
            
            <div class="card">
              <div class="card-block" id="n2016-neural-computers">
                <h4 class="card-title">Hybrid computing using a neural network with dynamic external memory</h4>
                <h6 class="card-subtitle text-muted"><strong>2016-neural-computers</strong></h6>
                <p class="card-text">Alex Graves; Greg Wayne; Malcolm Reynolds; Tim Harley; Ivo Danihelka; Agnieszka Grabska-Barwińska; Sergio Gómez Colmenarejo; Edward Grefenstette; Tiago Ramalho; John Agapiou; Adrià Puigdomènech Badia; Karl Moritz Hermann; Yori Zwols; Georg Ostrovski; Adam Cain; Helen King; Christopher Summerfield; Phil Blunsom; Koray Kavukcuoglu; Demis Hassabis</p>
                <p class="card-text">
                  
                  2016-10-12 (online)
                  
                  
                  
                </p>
                <p class="card-text">
                  <em>Nature (Nature)</em>.
                  538, 
                  7626, 
                  471-476. 
                  <a href="https://dx.doi.org/10.1038/nature20101">doi:10.1038/nature20101</a>
                  
                </p>
                
                <h6 class="m-b-0"><strong style="color: #444">Description</strong></h6>
                <p class="card-text">Augment deep networks with an external memory (RAM) matrix.</p>
<p class="card-text">Bart says: "TL;DR: This work follows a line of research that teaches deep-nets
to learn algorithmic tasks (addition, sorting, multiplication, key-value look-up).
This paper goes a bit further and teaches their network to do shortest-path finding
in graphs and demonstrates on maps of the London underground. Cool demo with nice results,
but the hype-machine has blown it out of proportion
(check out the FT article for a breathless take claiming thinking computers are one step closer...)"</p>
<p class="card-text"></p>
                

                

                

                
                <p class="card-text">
                  
                  <span class="tag tag-primary">machine-learning</span>
                  
                  <span class="tag tag-primary">deep-learning</span>
                  
                </p>
                
              </div>
            </div>
            
            
            <div class="card">
              <div class="card-block" id="n2016-aspuru-mol-feat">
                <h4 class="card-title">Automatic chemical design using a data-driven continuous representation
  of molecules</h4>
                <h6 class="card-subtitle text-muted"><strong>2016-aspuru-mol-feat</strong></h6>
                <p class="card-text">Rafael Gómez-Bombarelli; David Duvenaud; José Miguel Hernández-Lobato; Jorge Aguilera-Iparraguirre; Timothy D. Hirzel; Ryan P. Adams; Alán Aspuru-Guzik</p>
                <p class="card-text">
                  
                  2016-10-07 (online)
                  
                  
                  
                </p>
                <p class="card-text">
                  
                  
                  
                  
                  
                  <a href="https://arxiv.org/abs/1610.02415">arxiv:1610.02415</a>
                </p>
                
                <h6 class="m-b-0"><strong style="color: #444">Description</strong></h6>
                <p class="card-text">The authors train an auto-encoder to provide a vector representation
for small molecules. Small molecules are graphs with varying
sizes, so they're hard to feed into neural nets (which require
fixed-length bitvectors). By fusing together an encoder and decoder
(and making the "middle" representation sufficiently small), they
learn a vector representation.</p>
<p class="card-text">The authors lean heavily on <a href="#safe-css-arxiv151106349">arxiv:1511.06349 (ref. 25)</a> to autoencode
SMILES strings.</p>
<p class="card-text">They use a variational autoencoder (noisy) to avoid "dead zones"
in latent space.</p>
<p class="card-text">They optomize OLED properties as an example.</p>
<p class="card-text"></p>
                

                

                
                    <a data-toggle="collapse" href="#n2016-aspuru-mol-feat-cites"
                       aria-expanded="false" aria-controls="n2016-aspuru-mol-feat-cites">
                    Show References
                    </a>
                    <table class="table table-sm collapse" id="n2016-aspuru-mol-feat-cites">
                    <tr>
                    <th>Num</th><th>Entry</th><th>Why</th>
                    </tr>
                    
                        
                        <tr>
                        <td>25</td>
                        
                        <td><a href="#safe-css-arxiv151106349">arxiv:1511.06349</a></td>
                        
                        <td></td>
                        </tr>
                        
                    
                    </table>
                

                
                <p class="card-text">
                  
                  <span class="tag tag-primary">machine-learning</span>
                  
                  <span class="tag tag-primary">cheminformatics</span>
                  
                  <span class="tag tag-primary">misc</span>
                  
                </p>
                
              </div>
            </div>
            
            
            <div class="card">
              <div class="card-block" id="n2016-msm-cryptic-binding">
                <h4 class="card-title">Modelling proteins’ hidden conformations to predict antibiotic resistance</h4>
                <h6 class="card-subtitle text-muted"><strong>2016-msm-cryptic-binding</strong></h6>
                <p class="card-text">Kathryn M. Hart; Chris M. W. Ho; Supratik Dutta; Michael L. Gross; Gregory R. Bowman</p>
                <p class="card-text">
                  
                  2016-10-06 (online)
                  
                  
                  
                </p>
                <p class="card-text">
                  <em>Nature Communications (Nat. Commun.)</em>.
                  7, 
                  
                  12965. 
                  <a href="https://dx.doi.org/10.1038/ncomms12965">doi:10.1038/ncomms12965</a>
                  
                </p>
                
                <h6 class="m-b-0"><strong style="color: #444">Description</strong></h6>
                <p class="card-text">Labmate summarizes:</p>
<p class="card-text">They generated ensembles using MD, then docked to those ensembles, then re-weighted the docking scores
based on the MSM. This gave a huge improvement in the predictive power of docking to predict affinity/potency.
It turned an inverse relationship (when docking using xtal structures) into a highly correlated trend.</p>
<p class="card-text">They confirmed their hypothesis about the protein flexibility by using a mass spec. method.</p>
<p class="card-text">They identified a loop movement important in the anti-antibacterial activity of the enzyme that was different
from one previously proposed/suspected.</p>
<p class="card-text">They proposed mutants that would stabilize their proposed loop, and tested them experimentally.</p>
<p class="card-text">The power of using the MSM to re-weight other analyses is also very encouraging
to see yet again. Also note that they did all this with what looks like a pretty low amount of aggregate
sampling (few microseconds per mutant).</p>
<p class="card-text"></p>
                

                

                

                
                <p class="card-text">
                  
                  <span class="tag tag-primary">misc</span>
                  
                </p>
                
              </div>
            </div>
            
            
            <div class="card">
              <div class="card-block" id="n2016-mbar-volumes">
                <h4 class="card-title">Structural analysis of high-dimensional basins of attraction</h4>
                <h6 class="card-subtitle text-muted"><strong>2016-mbar-volumes</strong></h6>
                <p class="card-text">Stefano Martiniani; K. Julian Schrenk; Jacob D. Stevenson; David J. Wales; Daan Frenkel</p>
                <p class="card-text">
                  
                  2016-09-15 (online)
                  
                  
                  
                </p>
                <p class="card-text">
                  <em>Physical Review E (Phys. Rev. E)</em>.
                  94, 
                  3, 
                  
                  <a href="https://dx.doi.org/10.1103/PhysRevE.94.031301">doi:10.1103/PhysRevE.94.031301</a>
                  
                </p>
                
                <h6 class="m-b-0"><strong style="color: #444">Description</strong></h6>
                <p class="card-text">Use multistate benett acceptance (MBAR) to find volumes in high dimensions.</p>
<p class="card-text"></p>
                

                

                

                
                <p class="card-text">
                  
                  <span class="tag tag-primary">misc</span>
                  
                </p>
                
              </div>
            </div>
            
            
            <div class="card">
              <div class="card-block" id="n2016-guttenberg-deep-slow">
                <h4 class="card-title">Neural Coarse-Graining: Extracting slowly-varying latent degrees of
  freedom with neural networks</h4>
                <h6 class="card-subtitle text-muted"><strong>2016-guttenberg-deep-slow</strong></h6>
                <p class="card-text">Nicholas Guttenberg; Martin Biehl; Ryota Kanai</p>
                <p class="card-text">
                  
                  2016-09-01 (online)
                  
                  
                  
                </p>
                <p class="card-text">
                  
                  
                  
                  
                  
                  <a href="https://arxiv.org/abs/1609.00116">arxiv:1609.00116</a>
                </p>
                
                <h6 class="m-b-0"><strong style="color: #444">Description</strong></h6>
                <p class="card-text">Somehow uses deep networks to extract slow modes from dynamical signals.</p>
<p class="card-text"></p>
                

                

                

                
                <p class="card-text">
                  
                  <span class="tag tag-primary">machine-learning</span>
                  
                  <span class="tag tag-primary">deep-learning</span>
                  
                </p>
                
              </div>
            </div>
            
            
            <div class="card">
              <div class="card-block" id="safe-css-arxiv151106349">
                <h4 class="card-title">Generating Sentences from a Continuous Space</h4>
                <h6 class="card-subtitle text-muted"><strong>arxiv:1511.06349</strong></h6>
                <p class="card-text">Samuel R. Bowman; Luke Vilnis; Oriol Vinyals; Andrew M. Dai; Rafal Jozefowicz; Samy Bengio</p>
                <p class="card-text">
                  
                  2015-11-19 (online)
                  
                  
                  
                </p>
                <p class="card-text">
                  
                  
                  
                  
                  
                  <a href="https://arxiv.org/abs/1511.06349">arxiv:1511.06349</a>
                </p>
                
                <h6 class="m-b-0"><strong style="color: #444">Description</strong></h6>
                <p class="card-text">Advances in autoencoding text, used by <a href="#n2016-aspuru-mol-feat">2016-aspuru-mol-feat</a>.
</p>
                

                

                

                
                <p class="card-text">
                  
                  <span class="tag tag-primary">misc</span>
                  
                </p>
                
              </div>
            </div>
            
            
            <div class="card">
              <div class="card-block" id="n2014-ganguli-saddle-points">
                <h4 class="card-title">Identifying and attacking the saddle point problem in high-dimensional
  non-convex optimization</h4>
                <h6 class="card-subtitle text-muted"><strong>2014-ganguli-saddle-points</strong></h6>
                <p class="card-text">Yann Dauphin; Razvan Pascanu; Caglar Gulcehre; Kyunghyun Cho; Surya Ganguli; Yoshua Bengio</p>
                <p class="card-text">
                  
                  2014-06-10 (online)
                  
                  
                  
                </p>
                <p class="card-text">
                  
                  
                  
                  
                  
                  <a href="https://arxiv.org/abs/1406.2572">arxiv:1406.2572</a>
                </p>
                
                <h6 class="m-b-0"><strong style="color: #444">Description</strong></h6>
                <p class="card-text">Labmate summarizes:</p>
<p class="card-text">This one is a really cool paper.  One of those "we've all been doing it wrong" papers that could have a big
impact.  Their main conclusions are</p>
<p class="card-text">1. When optimizing functions in high dimensional spaces, saddle points are a much bigger problem than local
minima.  There are far more of them, and the few local minima that do exist mostly have values only slightly
worse than the global minimum.</p>
<p class="card-text">2. Standard optimization methods deal really badly with saddle points (and hence work really badly in high
dimensional spaces).  First order methods like gradient descent start taking tiny steps, so they take a really
long time to escape.  Quasi-Newton methods are even worse.  They just converge to the saddle point and never escape.</p>
<p class="card-text">3. They describe a new approach that doesn't have these problems and goes right through saddle points without
slowing down.</p>
<p class="card-text">They do all this in the context of neural networks, but it likely applies just as well to other high dimensional
optimization problems.  Proteins, for example.  When you use an algorithm like L-BFGS for energy minimization,
it's probably converging to a saddle point, not a local minimum.  It could be really interesting to try their
method.  Could we fold a protein to the native state just by a straightforward energy minimization?</p>
<p class="card-text">Force field optimization is another case whether this approach could be really useful.</p>
<p class="card-text">They also show that at a saddle point, there's a strong monotonic relationship between the error and the
fraction of negative eigenvalues of the Hessian.  Potentially that could be used as a way to measure how
far you are from the global minimum.  For example, when optimizing force field parameters, it would tell you
whether your parameters are close to optimal, or whether there's still a lot of room to improve them further.</p>
<p class="card-text"></p>
                

                

                

                
                <p class="card-text">
                  
                  <span class="tag tag-primary">misc</span>
                  
                  <span class="tag tag-primary">machine-learning</span>
                  
                  <span class="tag tag-primary">deep-learning</span>
                  
                </p>
                
              </div>
            </div>
            
            <hr style="margin: 2rem">
            
        </div>
        <div class="col-xs-12 col-lg-3">
          <h4>Items</h4>
          <div id="navlist">
            <ul class="nav">
              
              
              <li class="nav-item">
                <a class="nav-link" href="#n2017-baker-antibody-design">2017-baker-antibody-design</a>
              </li>
            
              
              <li class="nav-item">
                <a class="nav-link" href="#n2017-deep-lift">2017-deep-lift</a>
              </li>
            
              
              <li class="nav-item">
                <a class="nav-link" href="#n2016-neural-computers">2016-neural-computers</a>
              </li>
            
              
              <li class="nav-item">
                <a class="nav-link" href="#n2016-aspuru-mol-feat">2016-aspuru-mol-feat</a>
              </li>
            
              
              <li class="nav-item">
                <a class="nav-link" href="#n2016-msm-cryptic-binding">2016-msm-cryptic-binding</a>
              </li>
            
              
              <li class="nav-item">
                <a class="nav-link" href="#n2016-mbar-volumes">2016-mbar-volumes</a>
              </li>
            
              
              <li class="nav-item">
                <a class="nav-link" href="#n2016-guttenberg-deep-slow">2016-guttenberg-deep-slow</a>
              </li>
            
              
              <li class="nav-item">
                <a class="nav-link" href="#safe-css-arxiv151106349">arxiv:1511.06349</a>
              </li>
            
              
              <li class="nav-item">
                <a class="nav-link" href="#n2014-ganguli-saddle-points">2014-ganguli-saddle-points</a>
              </li>
            
            </ul>
          </div>
        </div>
      </div>
    </div>

    <!-- jQuery first, then Tether, then Bootstrap JS. -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.0.0/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.2.0/js/tether.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.4/js/bootstrap.min.js"></script>
    <script src="https://use.fontawesome.com/f678e12fb6.js"></script>
    <script>$('body').scrollspy({target: '#navlist'})</script>
  </body>
</html>